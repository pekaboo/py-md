# 如何处理重复消息？

**难度**：中等

**创建时间**：2025-10-06 15:38:32

## 答案
处理重复消息是分布式系统和消息队列中的常见挑战，可能导致数据不一致、业务逻辑错误或资源浪费。以下是系统化的解决方案，涵盖预防、检测、去重和容错机制，适用于不同场景（如支付、订单处理等）。

### **一、重复消息的来源**
1. **网络重试**：客户端或服务端因超时未收到响应，主动重试。
2. **消息队列重试**：消费者处理失败后，消息队列重新投递（如RabbitMQ的`nack`+`requeue`）。
3. **生产者重复发送**：业务逻辑错误或并发控制失效导致同一消息多次发送。
4. **消费者崩溃**：处理过程中消费者崩溃，未完成事务或未提交偏移量，重启后重新消费。

### **二、核心解决方案**
#### **1. 幂等性设计（核心方案）**
**定义**：同一操作多次执行的结果与一次执行相同。
**实现方式**：
- **唯一ID去重**：
  - 为每条消息生成全局唯一ID（如UUID、雪花算法ID）。
  - 消费者处理前检查ID是否已存在（数据库、Redis等）。
  - **示例**：支付系统用订单号作为唯一ID，重复请求直接返回成功。
- **业务状态标记**：
  - 在业务表中增加状态字段（如`status: pending/success/failed`）。
  - 处理前检查状态，若已成功则跳过。
  - **示例**：订单服务检查订单状态是否为`PAID`，避免重复扣款。
- **乐观锁控制**：
  - 使用版本号（`version`）或时间戳，更新时校验版本。
  - **SQL示例**：
    ```sql
    UPDATE accounts SET balance = balance - 100, version = version + 1 
    WHERE id = 123 AND version = 5;
    ```
  - 若影响行数为0，说明数据已变更，拒绝重复操作。

#### **2. 消息队列去重**
- **RabbitMQ**：
  - 使用`message-id`字段，消费者通过Redis记录已处理ID。
  - 开启`publisher confirms`和`consumer acknowledgements`，避免重复投递。
- **Kafka**：
  - 消费者提交偏移量（`offset`），确保消息仅被处理一次。
  - 结合事务性生产者（`transactions`）保证消息发送与业务操作原子性。
- **RocketMQ**：
  - 开启`consumeThreadMin`和`consumeThreadMax`控制并发，避免重复消费。
  - 使用`MessageExt`的`msgId`或业务自定义ID去重。

#### **3. 数据库层面去重**
- **唯一约束**：
  - 在关键字段（如订单号、用户ID）上添加唯一索引。
  - **示例**：
    ```sql
    ALTER TABLE orders ADD CONSTRAINT uk_order_no UNIQUE (order_no);
    ```
  - 插入重复数据时抛出异常，捕获后忽略或记录日志。
- **插入前查询**：
  - 先查询记录是否存在，再决定是否插入（性能较低，适合低频场景）。

#### **4. 分布式锁控制**
- **场景**：高并发下防止重复操作（如秒杀系统）。
- **实现**：
  - 使用Redis的`SETNX`或Redisson分布式锁。
  - **示例**：
    ```java
    RLock lock = redisson.getLock("order_lock_" + orderId);
    lock.lock();
    try {
        // 检查订单状态并处理
    } finally {
        lock.unlock();
    }
    ```

#### **5. 事务性消息（TCC模式）**
- **适用场景**：需要保证消息发送与业务操作一致性的场景（如跨库转账）。
- **步骤**：
  1. **Try**：预留资源（如冻结账户余额）。
  2. **Confirm**：确认操作（实际扣款）。
  3. **Cancel**：回滚操作（解冻余额）。
- **工具**：Seata、Hmily等分布式事务框架。

### **三、场景化解决方案**
#### **1. 支付系统**
- **问题**：用户重复点击支付按钮，导致重复扣款。
- **方案**：
  - 前端生成唯一支付请求ID，后端校验ID是否已处理。
  - 数据库订单表添加`status`字段，处理前检查状态。
  - 消息队列使用事务性生产者，确保支付成功后再发送通知。

#### **2. 订单系统**
- **问题**：用户重复提交订单，生成多个相同订单。
- **方案**：
  - 前端限制按钮点击频率（如1秒内仅允许一次）。
  - 后端生成订单号时校验是否已存在（唯一索引）。
  - 消息队列消费者使用Redis记录已处理订单号。

#### **3. 物联网设备上报**
- **问题**：设备网络不稳定导致重复上报数据。
- **方案**：
  - 设备为每条数据生成序列号，服务端校验序列号是否已接收。
  - 使用时间窗口过滤（如1分钟内相同设备的数据只处理一次）。

### **四、最佳实践**
1. **预防优于治理**：
   - 前端限制用户操作频率（如按钮防抖）。
   - 生产者发送消息时添加唯一ID。
2. **多层级去重**：
   - 结合消息队列ID、业务ID和数据库唯一约束。
3. **监控与告警**：
   - 记录重复消息数量，设置阈值告警。
   - 定期分析重复消息原因（如网络问题、代码逻辑错误）。
4. **测试验证**：
   - 模拟网络中断、消费者崩溃等场景，验证去重机制有效性。

### **五、工具与框架推荐**
| 工具/框架       | 适用场景                          | 核心功能                                  |
|------------------|-----------------------------------|-------------------------------------------|
| **Redis**        | 分布式锁、计数器、ID去重          | `SETNX`、`INCR`、哈希表存储已处理ID       |
| **Seata**        | 分布式事务                        | TCC、AT、SAGA模式                          |
| **Spring Retry**| 重试机制控制                      | 指数退避、最大重试次数                    |
| **Resilience4j** | 熔断、限流、重试                  | 结合Hystrix功能，支持Java生态              |
| **Kafka事务**    | 消息发送与业务操作原子性          | `produce()`和`commit()`事务封装           |

### **六、示例代码（Java + Redis去重）**
```java
public class OrderService {
    private final RedisTemplate<String, Boolean> redisTemplate;

    public boolean processOrder(String orderId) {
        // 1. 检查Redis是否已处理
        Boolean isProcessed = redisTemplate.opsForValue().get(orderId);
        if (Boolean.TRUE.equals(isProcessed)) {
            return true; // 跳过重复订单
        }

        // 2. 业务处理（如创建订单）
        try {
            createOrder(orderId);
            // 3. 标记为已处理（设置过期时间，避免Redis内存泄漏）
            redisTemplate.opsForValue().set(orderId, true, 24, TimeUnit.HOURS);
            return true;
        } catch (Exception e) {
            log.error("处理订单失败", e);
            return false;
        }
    }
}
```

### **七、总结**
- **核心原则**：通过唯一ID、幂等性、事务控制等手段，确保重复消息不影响业务结果。
- **分层设计**：从前端限制、生产者去重、消息队列控制到数据库校验，形成多级防护。
- **权衡选择**：根据业务场景（如实时性、一致性要求）选择合适方案，避免过度设计。
