# 线上 CPU 飙高如何排查？

**难度**：中等

**创建时间**：2025-10-06 15:48:04

## 答案
当线上服务的CPU使用率突然飙高时，通常意味着存在性能瓶颈或异常行为（如死循环、阻塞操作、高并发竞争等）。以下是系统化的排查步骤和工具，帮助快速定位问题根源：

---

## **一、初步确认问题**
### **1. 确认CPU飙高的现象**
- **观察指标**：通过监控系统（如Prometheus、Grafana、CloudWatch）查看CPU使用率是否持续接近100%，或出现周期性尖峰。
- **区分用户态/内核态**：
  - **用户态（User）**：Java进程等应用程序占用CPU。
  - **内核态（System）**：系统调用（如I/O、网络、锁竞争）占用CPU。
  - 工具：`top -c` 或 `htop`，按 `1` 查看每个逻辑核心的占用情况。

### **2. 判断是否为全局问题**
- **多实例对比**：如果是分布式服务，检查其他实例是否也有同样问题。若仅单个实例异常，可能是代码或配置问题；若全局异常，可能是依赖服务（如数据库、缓存）或流量突增。
- **负载均衡**：检查是否因流量倾斜导致某个节点过载。

---

## **二、定位高CPU的进程**
### **1. 查找占用CPU最高的进程**
```bash
top -c  # 实时查看进程CPU占用，按P排序
# 或
ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head -n 10  # 列出CPU占用前10的进程
```
- 记录高CPU进程的PID（如Java进程的PID）。

### **2. 确认进程类型**
```bash
ps -p <PID> -f  # 查看进程的启动命令和参数
```
- 如果是Java进程，确认是否为预期的业务进程（如避免误杀测试环境进程）。

---

## **三、定位高CPU的线程**
### **1. 查找进程内CPU占用高的线程**
```bash
top -H -p <PID>  # 查看指定进程的线程CPU占用，按P排序
# 或
ps -m <PID> -o pid,tid,pcpu,cmd | sort -k3 -nr | head -n 10  # 列出线程CPU占用前10
```
- 记录高CPU线程的TID（十进制）。

### **2. 将线程TID转换为十六进制**
```bash
printf "%x\n" <TID>  # 例如：TID=12345 → 十六进制=3039
```
- 后续分析JVM堆栈时需要十六进制TID。

---

## **四、分析线程堆栈（Java进程）**
### **1. 生成JVM线程堆栈**
```bash
jstack <PID> > thread_dump.log  # 生成完整线程堆栈
# 或
kill -3 <PID>  # 向进程发送SIGQUIT信号，输出堆栈到标准错误（需重定向到文件）
```

### **2. 搜索高CPU线程的堆栈**
```bash
grep -A 30 "nid=0x<十六进制TID>" thread_dump.log  # 例如：nid=0x3039
```
- 检查线程状态：
  - **RUNNABLE**：正在执行代码（可能是死循环、计算密集型任务）。
  - **BLOCKED**：等待锁（可能是死锁或锁竞争）。
  - **WAITING/TIMED_WAITING**：等待条件（如I/O、锁、线程池）。

### **3. 常见问题模式**
- **死循环**：堆栈中反复调用同一方法。
- **锁竞争**：多个线程阻塞在`synchronized`或`ReentrantLock`。
- **GC停顿**：频繁Full GC导致CPU飙高（需结合GC日志分析）。
- **JNI调用**：Native方法（如C/C++扩展）占用CPU。

---

## **五、分析系统调用（内核态CPU高）**
如果内核态CPU占用高，可能是系统调用频繁或I/O阻塞：
### **1. 使用`strace`跟踪系统调用**
```bash
strace -p <PID> -c  # 统计系统调用次数和耗时
strace -p <PID> -o strace.log  # 记录详细系统调用日志
```
- 常见问题：
  - 高频`read`/`write`：可能是磁盘I/O瓶颈。
  - 高频`epoll_wait`：可能是网络I/O阻塞。
  - 高频`futex`：可能是线程同步问题。

### **2. 使用`perf`分析性能事件**
```bash
perf top -p <PID>  # 实时查看进程的性能热点（函数级）
perf record -g -p <PID>  # 记录性能数据
perf report  # 分析记录的数据
```
- 识别热点函数（如`java.lang.String.hashCode`、`native`方法）。

---

## **六、分析JVM行为（用户态CPU高）**
### **1. 检查GC日志**
- 确认是否因频繁GC导致CPU飙高：
  ```bash
  -Xlog:gc*:file=gc.log  # JVM启动参数中启用GC日志
  ```
- 分析GC日志：
  - 频繁Full GC：可能是内存泄漏或老年代空间不足。
  - 长GC停顿：可能是大对象分配或碎片化严重。

### **2. 检查JVM参数**
- 确认堆大小（`-Xmx`/`-Xms`）是否合理，避免频繁扩容。
- 检查GC算法（如G1、CMS、ZGC）是否适合当前负载。

### **3. 使用JVM工具**
- **jstat**：监控GC和内存使用：
  ```bash
  jstat -gcutil <PID> 1s  # 每秒输出一次GC统计
  ```
- **jmap**：生成堆转储（Heap Dump）分析内存：
  ```bash
  jmap -dump:format=b,file=heap.hprof <PID>  # 生成堆转储文件
  # 使用MAT（Eclipse Memory Analyzer）分析内存泄漏
  ```

---

## **七、排查网络/I/O问题**
### **1. 检查网络连接**
```bash
netstat -anp | grep <PID>  # 查看进程的网络连接
ss -s  # 查看系统级网络统计
```
- 大量`TIME_WAIT`/`CLOSE_WAIT`：可能是连接未正确关闭。
- 高并发连接：可能是连接池配置不合理。

### **2. 检查磁盘I/O**
```bash
iostat -x 1  # 查看磁盘I/O延迟和吞吐量
iotop -oP <PID>  # 查看进程的磁盘I/O
```
- 高磁盘利用率：可能是日志写入或文件操作频繁。

---

## **八、常见问题与解决方案**
| **问题类型**       | **现象**                          | **解决方案**                                      |
|--------------------|-----------------------------------|-------------------------------------------------|
| **死循环**         | 线程堆栈中反复调用同一方法        | 修复代码逻辑，增加终止条件                        |
| **锁竞争**         | 大量线程阻塞在`synchronized`      | 优化锁粒度，使用`ReentrantLock`或并发集合          |
| **内存泄漏**       | 频繁Full GC，堆内存持续增长        | 使用MAT分析堆转储，修复对象引用未释放的问题        |
| **GC停顿过长**     | STW（Stop-The-World）时间过长     | 调整GC算法（如G1→ZGC），增大堆空间                |
| **系统调用频繁**   | 内核态CPU高，`strace`显示高频调用  | 优化I/O操作（如批量写入），减少不必要的系统调用     |
| **线程池耗尽**     | 任务队列堆积，线程全部忙碌          | 调整线程池核心/最大线程数，增加任务超时机制         |

---

## **九、预防措施**
1. **监控告警**：设置CPU使用率阈值告警（如持续5分钟>80%）。
2. **压力测试**：模拟高并发场景，提前发现性能瓶颈。
3. **代码审查**：避免在循环中执行耗时操作（如数据库查询）。
4. **资源隔离**：为关键服务分配独立资源（如容器、K8s Pod）。
5. **日志优化**：减少不必要的日志输出，避免磁盘I/O成为瓶颈。

---

## **十、总结排查流程**
1. **确认现象**：通过监控确认CPU飙高是否持续/周期性。
2. **定位进程**：使用`top`找到高CPU进程。
3. **定位线程**：使用`top -H`找到高CPU线程。
4. **分析堆栈**：使用`jstack`/`strace`/`perf`定位代码或系统问题。
5. **验证修复**：重启服务或回滚代码，观察CPU是否恢复正常。

**关键工具**：
- `top`/`htop`：实时监控进程和线程。
- `jstack`：分析Java线程堆栈。
- `strace`/`perf`：分析系统调用和性能热点。
- `jstat`/`jmap`：分析JVM内存和GC。

通过系统化的排查，可以快速定位并解决线上CPU飙高问题，保障服务稳定性。
